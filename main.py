from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
import openai
from dotenv import load_dotenv
import os
import httpx
import asyncio
import time
import random

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
telegram_token = os.getenv("TELEGRAM_TOKEN")

app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

MASKS = {
    "flirt": {
        "name": "–§–ª–∏—Ä—Ç",
        "prompt": "–¢—ã —Ñ–ª–∏—Ä—Ç—É–µ—à—å —Å —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º. –û–±—â–µ–Ω–∏–µ –ª—ë–≥–∫–æ–µ, –∏–≥—Ä–∏–≤–æ–µ, —Å –ø–æ–¥–¥—Ä–∞–∑–Ω–∏–≤–∞–Ω–∏–µ–º –∏ —É–ª—ã–±–∫–æ–π."
    },
    "rude": {
        "name": "–ì—Ä—É–±—ã–π",
        "prompt": "–¢—ã –≥–æ–≤–æ—Ä–∏—à—å —Ä–µ–∑–∫–æ, –≥—Ä—É–±–æ, —Å —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ–º –∏ –≤—ã–∑–æ–≤–æ–º. –ú–æ–∂–µ—à—å —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ —à—É—Ç–∏—Ç—å."
    },
    "friendly": {
        "name": "–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π",
        "prompt": "–¢—ã –æ–±—â–∞–µ—à—å—Å—è –º—è–≥–∫–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ, —Å —é–º–æ—Ä–æ–º –∏ —Å–æ—á—É–≤—Å—Ç–≤–∏–µ–º."
    }
}

user_styles = {}
last_active = {}        # chat_id: timestamp
was_pinged = {}         # chat_id: bool
chat_histories = {}     # chat_id: list of messages

@app.on_event("startup")
async def start_background_task():
    asyncio.create_task(background_checker())

@app.post("/webhook")
async def telegram_webhook(request: Request):
    payload = await request.json()
    chat_id = payload["message"]["chat"]["id"]
    text = payload["message"]["text"].lower()

    # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    last_active[chat_id] = time.time()
    was_pinged[chat_id] = False

    if chat_id not in chat_histories:
        chat_histories[chat_id] = []

    if text.startswith("/style"):
        return await handle_style_command(chat_id, text)

    if "—Ñ–æ—Ç–æ" in text:
        await save_message(chat_id, "user", text)
        await save_message(chat_id, "assistant", "[—Ñ–æ—Ç–æ]")
        return await send_telegram_message(chat_id, "[—Ñ–æ—Ç–æ]")

    if any(w in text for w in ["–≤–∏–¥–µ–æ", "–∫—Ä—É–∂–æ–∫", "–≥–æ–ª–æ—Å"]):
        reply = await generate_media_denial(chat_id, text)
        await save_message(chat_id, "user", text)
        await save_message(chat_id, "assistant", reply)
        return await send_telegram_message(chat_id, f"{reply}\n\nüé≠ –ú–∞—Å–∫–∞: {MASKS[get_style(chat_id)]['name']}")

    reply = await generate_reply(chat_id, text)
    await save_message(chat_id, "user", text)
    await save_message(chat_id, "assistant", reply)
    return await send_telegram_message(chat_id, f"{reply}\n\nüé≠ –ú–∞—Å–∫–∞: {MASKS[get_style(chat_id)]['name']}")

async def handle_style_command(chat_id: int, text: str):
    try:
        style_key = text.split(" ", 1)[1].strip()
    except IndexError:
        return await send_telegram_message(chat_id, "–£–∫–∞–∂–∏ —Å—Ç–∏–ª—å: /style flirt | rude | friendly")

    if style_key not in MASKS:
        return await send_telegram_message(chat_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∏–ª—å. –í–æ–∑–º–æ–∂–Ω—ã–µ: flirt, rude, friendly")

    user_styles[chat_id] = style_key
    return await send_telegram_message(chat_id, f"‚úÖ –ú–∞—Å–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞: {MASKS[style_key]['name']}")

def get_style(chat_id: int) -> str:
    return user_styles.get(chat_id, "friendly")

async def generate_reply(chat_id: int, user_text: str) -> str:
    style = get_style(chat_id)
    prompt = MASKS[style]["prompt"]
    messages = [{"role": "system", "content": prompt}] + chat_histories.get(chat_id, [])[-6:] + [
        {"role": "user", "content": user_text}
    ]
    try:
        response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GPT: {e}"

async def generate_media_denial(chat_id: int, user_text: str) -> str:
    tone = MASKS[get_style(chat_id)]["prompt"]
    instruction = (
        "–¢–µ–±—è –ø–æ–ø—Ä–æ—Å–∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ–¥–∏–∞ (–≤–∏–¥–µ–æ, –∫—Ä—É–∂–æ–∫, –≥–æ–ª–æ—Å). "
        "–¢—ã –Ω–µ –º–æ–∂–µ—à—å —ç—Ç–æ–≥–æ —Å–¥–µ–ª–∞—Ç—å. –û—Ç–≤–µ—Ç—å –≤ —Å—Ç–∏–ª–µ –º–∞—Å–∫–∏: " + tone +
        " –ù–∞–º–µ–∫–Ω–∏, –æ—Ç—à—É—Ç–∏—Å—å –∏–ª–∏ —Ñ–ª–∏—Ä—Ç—É–π, –Ω–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–π –º–µ–¥–∏–∞."
    )
    messages = [{"role": "system", "content": instruction}, {"role": "user", "content": user_text}]
    try:
        response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–∞–∑–µ –º–µ–¥–∏–∞: {e}"

async def send_telegram_message(chat_id: int, text: str):
    url = f"https://api.telegram.org/bot{telegram_token}/sendMessage"
    payload = {"chat_id": chat_id, "text": text}
    async with httpx.AsyncClient() as client:
        await client.post(url, json=payload)

async def save_message(chat_id: int, role: str, content: str):
    if chat_id not in chat_histories:
        chat_histories[chat_id] = []
    chat_histories[chat_id].append({"role": role, "content": content})

async def background_checker():
    while True:
        now = time.time()
        for chat_id, last_time in last_active.items():
            if was_pinged.get(chat_id):
                continue

            elapsed = now - last_time
            random_delay = random.randint(60, 120)  # –æ—Ç 1 –¥–æ 2 –º–∏–Ω—É—Ç

            if elapsed >= random_delay:
                reply = await generate_ping(chat_id)
                await send_telegram_message(chat_id, f"{reply}\n\nüé≠ –ú–∞—Å–∫–∞: {MASKS[get_style(chat_id)]['name']}")
                await save_message(chat_id, "assistant", reply)
                was_pinged[chat_id] = True

        await asyncio.sleep(30)

async def generate_ping(chat_id: int) -> str:
    prompt = MASKS[get_style(chat_id)]["prompt"]
    messages = [{"role": "system", "content": prompt}] + chat_histories.get(chat_id, [])[-6:] + [
        {"role": "user", "content": "–¢—ã —Ö–æ—á–µ—à—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä, –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–ª—á–∏—Ç. –û—Ç–≤–µ—Ç—å –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–º —Å—Ç–∏–ª–µ."}
    ]
    try:
        response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"ü§ñ (–Ω–µ —Å–º–æ–≥ –ø–∏–Ω–≥–∞–Ω—É—Ç—å): {e}"
