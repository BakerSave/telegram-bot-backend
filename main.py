from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse

import openai
from dotenv import load_dotenv
import os

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/message", response_class=HTMLResponse)
chat_history = []

@app.get("/message", response_class=HTMLResponse)
def get_message(text: str):
  global chat_history

  if not chat_history:
      chat_history.append({"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."})

  chat_history.append({"role": "user", "content": text})

  print("üì§ PROMPT to GPT:", chat_history)

  try:
      response = openai.ChatCompletion.create(
          model="gpt-3.5-turbo",
          messages=chat_history,
      )
      reply = response["choices"][0]["message"]["content"]
      chat_history.append({"role": "assistant", "content": reply})
  except Exception as e:
      reply = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}"

  # –¢–µ–∫—Å—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –±—Ä–∞—É–∑–µ—Ä–µ
  history_debug = "<br>".join([
      f"<b>{msg['role']}:</b> {msg['content']}" for msg in chat_history
  ])

  return f"""
  <html>
      <body>
          <h2>–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏: {text}</h2>
          <p><b>–û—Ç–≤–µ—Ç GPT:</b> {reply}</p>
          <h3>ü™µ –û—Ç–ª–∞–¥–∫–∞: —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª–æ—Å—å –≤ GPT</h3>
          <div style='background:#f0f0f0; padding:10px; border:1px solid #ccc;'>{history_debug}</div>
          <br>
          <img src="/static/cat.jpg" width="300">
      </body>
  </html>
  """
  <html>
      <body>
          <h2>–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏: {text}</h2>
          <p><b>–û—Ç–≤–µ—Ç GPT:</b> {reply}</p>
          <img src="/static/cat.jpg" width="300">
      </body>
  </html>
  """
