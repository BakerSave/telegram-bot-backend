from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse

import openai
from dotenv import load_dotenv
import os

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()
chat_history = []

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/message", response_class=HTMLResponse)
def get_message(text: str):
    global chat_history

    if not chat_history:
        chat_history.append({"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."})

    chat_history.append({"role": "user", "content": text})

    print("üì§ PROMPT to GPT:", chat_history)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=chat_history,
        )
        reply = response["choices"][0]["message"]["content"]
        chat_history.append({"role": "assistant", "content": reply})
    except Exception as e:
        reply = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}"

    history_debug = "<br>".join([
        f"<b>{msg['role']}:</b> {msg['content']}" for msg in chat_history
    ])

    return f"""
    <html>
        <body>
            <h2>–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏: {text}</h2>
            <p><b>–û—Ç–≤–µ—Ç GPT:</b> {reply}</p>
            <h3> –¢–µ–∫—É—â–∏–π –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç GPT</h3>
            <div style='background:#f0f0f0; padding:10px; border:1px solid #ccc;'>{history_debug}</div>
            <br>
            <img src="/static/psycho.jpg" width="300">
        </body>
    </html>
    """
