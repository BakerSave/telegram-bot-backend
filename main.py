from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
import openai
from dotenv import load_dotenv
import os
import httpx

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
telegram_token = os.getenv("TELEGRAM_TOKEN")

app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

# System-–ø—Ä–æ–º–ø—Ç—ã (—Ç—ã –º–æ–∂–µ—à—å –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–∑–∂–µ)
system_prompts = {
    "—à–∞–±–ª–æ–Ω1": "–¢—ã –≤–µ–¥—ë—à—å —Å–µ–±—è –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –º—è–≥–∫–æ, –ª–∞—Å–∫–æ–≤–æ.",
    "—à–∞–±–ª–æ–Ω2": "–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –∂—ë—Å—Ç–∫–æ, —Ä–∞–∑–¥—Ä–∞–∂—ë–Ω–Ω–æ –∏ –Ω–µ–º–Ω–æ–≥–æ –≥—Ä—É–±–æ.",
    "—à–∞–±–ª–æ–Ω3": "–¢—ã –≥–æ–≤–æ—Ä–∏—à—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ, —Ä–æ–≤–Ω–æ –∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ."
}


@app.post("/webhook")
async def telegram_webhook(request: Request):
    payload = await request.json()
    print("üì® –í—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç Telegram:", payload)

    try:
        chat_id = payload["message"]["chat"]["id"]
        text = payload["message"]["text"]

        reply = await get_gpt_reply(text)
        await send_telegram_message(chat_id, reply)

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ:", e)

    return {"ok": True}


async def get_gpt_reply(user_text: str) -> str:
    # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–º, –∫–∞–∫ —Å –±–æ—Ç–æ–º —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—é—Ç
    prompt_mode = await detect_prompt_mode_with_gpt(user_text)
    system_prompt = system_prompts[prompt_mode]

    print(f"üß† –¢–æ–Ω —Å–æ–æ–±—â–µ–Ω–∏—è: {prompt_mode}")
    print(f"üì• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª: {user_text}")

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_text}
    ]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
        )
        reply = response["choices"][0]["message"]["content"]
        return reply
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GPT: {e}"


async def detect_prompt_mode_with_gpt(user_text: str) -> str:
    """GPT —Å–∞–º –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç, –∫–∞–∫ —Å –Ω–∏–º –≥–æ–≤–æ—Ä—è—Ç: –≤–µ–∂–ª–∏–≤–æ, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ."""
    classification_prompt = [
        {"role": "system", "content": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–æ–Ω —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: '–≤–µ–∂–ª–∏–≤–æ–µ', '–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ' –∏–ª–∏ '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ'."},
        {"role": "user", "content": user_text}
    ]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=classification_prompt,
        )
        result = response["choices"][0]["message"]["content"].strip().lower()
        print(f"üìä GPT –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –∫–∞–∫: {result}")

        if "–≤–µ–∂–ª–∏–≤" in result:
            return "—à–∞–±–ª–æ–Ω1"
        if "–∞–≥—Ä–µ—Å—Å" in result:
            return "—à–∞–±–ª–æ–Ω2"
        return "—à–∞–±–ª–æ–Ω3"

    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:", e)
        return "—à–∞–±–ª–æ–Ω3"


async def send_telegram_message(chat_id: int, text: str):
    url = f"https://api.telegram.org/bot{telegram_token}/sendMessage"
    payload = {"chat_id": chat_id, "text": text}
    async with httpx.AsyncClient() as client:
        await client.post(url, json=payload)
