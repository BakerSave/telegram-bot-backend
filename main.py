from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse

import openai
from dotenv import load_dotenv
import os

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()
chat_history = []

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/message", response_class=HTMLResponse)
def get_message(text: str):
    global chat_history

    if not chat_history:
        chat_history.append({"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."})

    chat_history.append({"role": "user", "content": text})
    print("PROMPT to GPT:", chat_history)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=chat_history,
        )
        reply = response["choices"][0]["message"]["content"]
        chat_history.append({"role": "assistant", "content": reply})
    except Exception as e:
        reply = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}"

    history_debug = "<br>".join([
        f"<b>{msg['role']}:</b> {msg['content']}" for msg in chat_history
    ])

    return f"""
    <html>
        <body>
            <h2>–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏: {text}</h2>
            <p><b>–û—Ç–≤–µ—Ç GPT:</b> {reply}</p>
            <h3> –¢–µ–∫—É—â–∏–π –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç GPT</h3>
            <div style='background:#f0f0f0; padding:10px; border:1px solid #ccc;'>{history_debug}</div>
            <br>
            <img src="/static/psycho.jpg" width="300">
        </body>
    </html>
    """

from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse

import openai
from dotenv import load_dotenv
import os
import httpx

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
telegram_token = os.getenv("TELEGRAM_TOKEN")  # –î–æ–±–∞–≤—å —ç—Ç—É –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ Railway ‚Üí Variables

app = FastAPI()
chat_history = []

app.mount("/static", StaticFiles(directory="static"), name="static")


@app.post("/webhook")
async def telegram_webhook(request: Request):
    payload = await request.json()
    print("–í—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç Telegram:", payload)

    try:
        chat_id = payload["message"]["chat"]["id"]
        text = payload["message"]["text"]

        reply = get_message(text)

        await send_telegram_message(chat_id, reply)

    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è:", e)

    return {"ok": True}


def get_message(text: str):
    global chat_history

    if not chat_history:
        chat_history.append({"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."})

    chat_history.append({"role": "user", "content": text})
    print("üì§ PROMPT to GPT:", chat_history)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=chat_history,
        )
        reply = response["choices"][0]["message"]["content"]
        chat_history.append({"role": "assistant", "content": reply})
        return reply
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}"


async def send_telegram_message(chat_id: int, text: str):
    url = f"https://api.telegram.org/bot{telegram_token}/sendMessage"
    payload = {"chat_id": chat_id, "text": text}
    async with httpx.AsyncClient() as client:
        await client.post(url, json=payload)

